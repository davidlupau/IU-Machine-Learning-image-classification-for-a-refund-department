{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Feature extraction\n",
    "The feature extraction pipeline consists of two main functions. extract_enhanced_features processes individual images by extracting comprehensive visual characteristics including shape metrics (symmetry, contours), texture patterns (using LBP and GLCM), edge information (using Sobel and Canny), and color features across multiple color spaces (RGB, HSV, LAB). The process_all_images function applies this extraction to our entire dataset of 42,000 images, creating checkpoints every 1000 images and handling any failures gracefully, ultimately producing a feature matrix that maps each image's visual characteristics to its product category.\n"
   ],
   "id": "fe517832fe7d3c75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def extract_enhanced_features(image):\n",
    "   \"\"\"Enhanced feature extraction with computer vision techniques\"\"\"\n",
    "   try:\n",
    "       # Load and prepare image\n",
    "       if isinstance(image, str):\n",
    "           image = Image.open(image)\n",
    "       image = image.convert('RGB')\n",
    "       image = image.resize((60, 80))\n",
    "       img_array = np.array(image)\n",
    "       gray_image = np.mean(img_array, axis=2).astype(np.uint8)\n",
    "\n",
    "       # 1. Shape Features\n",
    "       shape_features = {\n",
    "           'aspect_ratio': img_array.shape[0] / img_array.shape[1],\n",
    "           'vertical_symmetry': np.mean(np.abs(gray_image - np.flipud(gray_image))),\n",
    "           'horizontal_symmetry': np.mean(np.abs(gray_image - np.fliplr(gray_image))),\n",
    "           'diagonal_symmetry': np.mean(np.abs(gray_image - np.rot90(np.rot90(gray_image)))),\n",
    "           'quadrant_symmetry': np.mean([np.abs(gray_image[:gray_image.shape[0]//2, :gray_image.shape[1]//2] -\n",
    "                                       gray_image[gray_image.shape[0]//2:, gray_image.shape[1]//2:])])\n",
    "       }\n",
    "\n",
    "       # Add contour features\n",
    "       contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "       if contours:\n",
    "           main_contour = max(contours, key=cv2.contourArea)\n",
    "           shape_features.update({\n",
    "               'contour_area': cv2.contourArea(main_contour),\n",
    "               'contour_perimeter': cv2.arcLength(main_contour, True),\n",
    "               'contour_circularity': (4 * np.pi * cv2.contourArea(main_contour)) /\n",
    "                                    (cv2.arcLength(main_contour, True) ** 2) if cv2.arcLength(main_contour, True) > 0 else 0\n",
    "           })\n",
    "\n",
    "       # 2. Texture Features\n",
    "       lbp = feature.local_binary_pattern(gray_image, P=8, R=1)\n",
    "       texture_features = {\n",
    "           'texture_mean': lbp.mean(),\n",
    "           'texture_var': lbp.var(),\n",
    "           'texture_uniformity': len(np.unique(lbp)) / len(lbp.flatten())\n",
    "       }\n",
    "\n",
    "       # GLCM features\n",
    "       angles = [0, 45, 90, 135]\n",
    "       glcm = graycomatrix(gray_image, distances=[1, 2], angles=angles, normed=True)\n",
    "       for angle_idx, angle in enumerate(angles):\n",
    "           texture_features.update({\n",
    "               f'glcm_contrast_{angle}': graycoprops(glcm, 'contrast')[0, angle_idx],\n",
    "               f'glcm_homogeneity_{angle}': graycoprops(glcm, 'homogeneity')[0, angle_idx],\n",
    "               f'glcm_energy_{angle}': graycoprops(glcm, 'energy')[0, angle_idx],\n",
    "               f'glcm_correlation_{angle}': graycoprops(glcm, 'correlation')[0, angle_idx]\n",
    "           })\n",
    "\n",
    "       # 3. Edge Features\n",
    "       sobel_h = ndimage.sobel(gray_image, axis=0)\n",
    "       sobel_v = ndimage.sobel(gray_image, axis=1)\n",
    "       edge_magnitude = np.sqrt(sobel_h**2 + sobel_v**2)\n",
    "       canny_edges = feature.canny(gray_image, sigma=1.0)\n",
    "\n",
    "       edge_features = {\n",
    "           'edge_density': np.mean(edge_magnitude),\n",
    "           'edge_variance': np.var(edge_magnitude),\n",
    "           'horizontal_edges': np.mean(np.abs(sobel_h)),\n",
    "           'vertical_edges': np.mean(np.abs(sobel_v)),\n",
    "           'canny_edge_density': np.mean(canny_edges),\n",
    "           'edge_magnitude_mean': np.mean(edge_magnitude),\n",
    "           'edge_magnitude_std': np.std(edge_magnitude)\n",
    "       }\n",
    "\n",
    "       # Edge direction histogram\n",
    "       edge_angles = np.arctan2(sobel_v, sobel_h) * 180 / np.pi\n",
    "       hist, _ = np.histogram(edge_angles[edge_magnitude > edge_magnitude.mean()],\n",
    "                            bins=12, range=(-180, 180))\n",
    "       for i, count in enumerate(hist):\n",
    "           edge_features[f'edge_direction_bin_{i}'] = count\n",
    "       edge_features['edge_direction_entropy'] = stats.entropy(hist + 1)\n",
    "\n",
    "       # 4. Color Features\n",
    "       color_features = {}\n",
    "\n",
    "       # RGB features\n",
    "       for idx, channel in enumerate(['red', 'green', 'blue']):\n",
    "           channel_data = img_array[:,:,idx]\n",
    "           color_features.update({\n",
    "               f'mean_{channel}': channel_data.mean(),\n",
    "               f'std_{channel}': channel_data.std(),\n",
    "               f'skew_{channel}': stats.skew(channel_data.flatten()),\n",
    "               f'kurtosis_{channel}': stats.kurtosis(channel_data.flatten())\n",
    "           })\n",
    "\n",
    "       # HSV features\n",
    "       hsv_image = cv2.cvtColor(img_array, cv2.COLOR_RGB2HSV)\n",
    "       for idx, channel in enumerate(['hue', 'saturation', 'value']):\n",
    "           channel_data = hsv_image[:,:,idx]\n",
    "           color_features.update({\n",
    "               f'mean_{channel}': channel_data.mean(),\n",
    "               f'std_{channel}': channel_data.std(),\n",
    "               f'kurtosis_{channel}': stats.kurtosis(channel_data.flatten())\n",
    "           })\n",
    "\n",
    "       # LAB color space features\n",
    "       lab_image = cv2.cvtColor(img_array, cv2.COLOR_RGB2LAB)\n",
    "       for idx, channel in enumerate(['l', 'a', 'b']):\n",
    "           channel_data = lab_image[:,:,idx]\n",
    "           color_features.update({\n",
    "               f'mean_{channel}': np.mean(channel_data),\n",
    "               f'std_{channel}': np.std(channel_data),\n",
    "               f'kurtosis_{channel}': stats.kurtosis(channel_data.flatten())\n",
    "           })\n",
    "\n",
    "       # Color histogram features\n",
    "       for idx, channel in enumerate(['red', 'green', 'blue']):\n",
    "           hist, _ = np.histogram(img_array[:,:,idx], bins=8, range=(0, 256))\n",
    "           for bin_idx, count in enumerate(hist):\n",
    "               color_features[f'{channel}_hist_bin_{bin_idx}'] = count\n",
    "\n",
    "       return {**shape_features, **texture_features, **edge_features, **color_features}\n",
    "\n",
    "   except Exception as e:\n",
    "       print(f\"Error in feature extraction: {str(e)}\")\n",
    "       return None\n",
    "\n",
    "def process_all_images(valid_data):\n",
    "   \"\"\"Process all images and create feature matrix\"\"\"\n",
    "   image_paths = valid_data['image_path'].tolist()\n",
    "   print(f\"Starting to process {len(image_paths)} images...\")\n",
    "\n",
    "   features_list = []\n",
    "   processed_paths = []\n",
    "   failed_paths = []\n",
    "\n",
    "   for idx, image_path in enumerate(tqdm(image_paths, desc=\"Extracting features\")):\n",
    "       try:\n",
    "           features = extract_enhanced_features(image_path)\n",
    "\n",
    "           if features is not None:\n",
    "               # Add image ID and category\n",
    "               image_id = os.path.basename(image_path).split('.')[0]\n",
    "               features['image_id'] = image_id\n",
    "               features['category'] = valid_data.loc[valid_data['image_path'] == image_path, 'categories'].iloc[0]\n",
    "\n",
    "               features_list.append(features)\n",
    "               processed_paths.append(image_path)\n",
    "           else:\n",
    "               failed_paths.append(image_path)\n",
    "\n",
    "           # Checkpoint every 1000 images\n",
    "           if (idx + 1) % 1000 == 0:\n",
    "               print(f\"\\nCheckpoint: Processed {idx + 1} images\")\n",
    "               pd.DataFrame(features_list).to_csv(f'features_checkpoint_{idx + 1}.csv', index=False)\n",
    "\n",
    "       except Exception as e:\n",
    "           print(f\"\\nError processing {image_path}: {str(e)}\")\n",
    "           failed_paths.append(image_path)\n",
    "\n",
    "   # Save results\n",
    "   feature_matrix = pd.DataFrame(features_list)\n",
    "   feature_matrix.to_csv('final_feature_matrix.csv', index=False)\n",
    "\n",
    "   if failed_paths:\n",
    "       with open('failed_images.txt', 'w') as f:\n",
    "           f.write('\\n'.join(failed_paths))\n",
    "\n",
    "   print(\"\\nProcessing Complete!\")\n",
    "   print(f\"Successfully processed: {len(processed_paths)} images\")\n",
    "   print(f\"Failed to process: {len(failed_paths)} images\")\n",
    "   print(f\"Total features per image: {len(feature_matrix.columns) - 2}\")\n",
    "\n",
    "   return feature_matrix, processed_paths, failed_paths"
   ],
   "id": "c82e20a4b1d7e802"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Testing\n",
    "Before processing our full dataset of 42,000 images, we conducted two testing phases. First, we tested feature extraction on a single image (B000HYL1V6.jpg from Arts, Crafts & Sewing category), successfully extracting 101 features across shape, texture, edge, and color characteristics. After confirming the feature extraction works correctly on this test case, despite a minor overflow warning that doesn't impact feature quality, we now proceed to full dataset processing which will create checkpoints every 1000 images to track progress and ensure data persistence.\n",
    "\n",
    "## With one picture"
   ],
   "id": "265a0c2e00a8da99"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Test code for single image feature extraction\n",
    "import pandas as pd\n",
    "from functions import extract_enhanced_features\n",
    "\n",
    "# Load the CSV and get first image path\n",
    "CSV_PATH = \"../Dataset/styles.csv\"\n",
    "IMAGES_DIR = \"../Dataset/train_images\"\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "test_image = f\"{IMAGES_DIR}/{df['ImgId'].iloc[0]}.jpg\"\n",
    "\n",
    "print(f\"Testing with image: {test_image}\")\n",
    "print(f\"Category: {df['categories'].iloc[0]}\")\n",
    "\n",
    "# Extract features\n",
    "features = extract_enhanced_features(test_image)\n",
    "\n",
    "if features:\n",
    "   print(\"\\nFeature extraction successful!\")\n",
    "   print(f\"Number of features extracted: {len(features)}\")\n",
    "   print(\"\\nSample features:\")\n",
    "   print(\"- Shape:\", list(features.keys())[:3])\n",
    "   print(\"- Texture:\", [k for k in features.keys() if 'texture' in k][:3])\n",
    "   print(\"- Edge:\", [k for k in features.keys() if 'edge' in k][:3])\n",
    "   print(\"- Color:\", [k for k in features.keys() if 'color' in k or 'mean_' in k][:3])\n",
    "else:\n",
    "   print(\"Feature extraction failed\")"
   ],
   "id": "1c107e882e0f57df"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## With all images",
   "id": "ec3187599045f777"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from functions import connect_dataset, process_all_images\n",
    "\n",
    "# Load and verify dataset\n",
    "CSV_PATH = \"../Dataset/styles.csv\"\n",
    "IMAGES_DIR = \"../Dataset/train_images\"\n",
    "valid_df, missing = connect_dataset(CSV_PATH, IMAGES_DIR)\n",
    "\n",
    "# Process all images\n",
    "feature_matrix, processed_paths, failed_paths = process_all_images(valid_df)"
   ],
   "id": "80d171034fb9e7a7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## _Optional_ Analyzing features\n",
    "The analyze_feature_importance function provides insights into how Random Forest classifier makes its decisions by examining which features contribute most significantly to the classification process. It extracts importance scores from the trained model, creates a ranked visualization of the top 15 most influential features, and saves this as a bar plot. By analyzing these feature importances, we can understand which visual characteristics (such as shape, texture, edge, or color features) are most crucial for distinguishing between different product categories, helping us validate our feature engineering approach and potentially identify areas for improvement in our image processing pipeline.\n",
    "\n",
    "Run analyze_features.py"
   ],
   "id": "f8a3a4c43a3e36b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def analyze_feature_importance(rf_classifier, feature_names, top_n=15):\n",
    "    # Get feature importances\n",
    "    importances = rf_classifier.feature_importances_\n",
    "\n",
    "    # Create DataFrame of features and their importance scores\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importances\n",
    "    })\n",
    "\n",
    "    # Sort by importance\n",
    "    feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "    # Plot top N features\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='importance', y='feature',\n",
    "                data=feature_importance.head(top_n))\n",
    "    plt.title(f'Top {top_n} Most Important Features')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importance.png')\n",
    "    plt.close()"
   ],
   "id": "70bbfd69f397a836"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Console output",
   "id": "60565e1e25293459"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "Top 15 Most Important Features:\n",
    "                 feature  importance\n",
    "72            kurtosis_a    0.016923\n",
    "75            kurtosis_b    0.015960\n",
    "10       glcm_contrast_0    0.014873\n",
    "19   glcm_homogeneity_90    0.014120\n",
    "74                 std_b    0.013996\n",
    "9     texture_uniformity    0.013952\n",
    "63   kurtosis_saturation    0.013726\n",
    "46              mean_red    0.013725\n",
    "62        std_saturation    0.013680\n",
    "22     glcm_contrast_135    0.013539\n",
    "41  edge_direction_bin_8    0.013379\n",
    "11    glcm_homogeneity_0    0.013199\n",
    "60          kurtosis_hue    0.013171\n",
    "59               std_hue    0.013104\n",
    "4           contour_area    0.013068"
   ],
   "id": "b386282c3e3e9cf7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
