{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model training\n",
    "The model training process begins by loading our feature matrix containing 10+ features extracted from 42,000 product images across 21 categories. Before training, we implement crucial data cleaning steps: handling infinite values, filling missing values with column means, and clipping extreme values using quantile-based boundaries. We then use GridSearchCV with a Random Forest Classifier to find the optimal model parameters, testing various combinations of estimators, tree depth, and sample thresholds. The process includes 5-fold cross-validation to ensure robust model performance and generates evaluation metrics and visualizations including a confusion matrix and ROC curves to assess the model's classification capabilities across all product categories."
   ],
   "id": "32cfa985e7ed92fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def main():\n",
    "    try:\n",
    "        # Load and prepare data\n",
    "        print(\"Loading feature matrix...\")\n",
    "        feature_matrix = pd.read_csv('final_feature_matrix.csv')\n",
    "\n",
    "        print(f\"\\nInitial feature matrix shape: {feature_matrix.shape}\")\n",
    "        print(f\"Categories present: {feature_matrix['category'].unique()}\")\n",
    "\n",
    "        # Clean the data\n",
    "        print(\"\\nCleaning feature matrix...\")\n",
    "        # Get all numeric columns except 'image_id'\n",
    "        feature_columns = feature_matrix.select_dtypes(include=[np.number]).columns\n",
    "        X = feature_matrix[feature_columns]\n",
    "        y = feature_matrix['category']\n",
    "\n",
    "        # Handle infinite and very large values\n",
    "        print(\"Handling infinite and extreme values...\")\n",
    "        X = X.replace([np.inf, -np.inf], np.nan)\n",
    "        X = X.fillna(X.mean(axis=0))  # Fill NaN with column means\n",
    "\n",
    "        # Calculate quantiles for each column\n",
    "        lower_bounds = X.quantile(0.01, axis=0)\n",
    "        upper_bounds = X.quantile(0.99, axis=0)\n",
    "\n",
    "        # Clip values column by column\n",
    "        for column in X.columns:\n",
    "            X[column] = X[column].clip(lower=lower_bounds[column], upper=upper_bounds[column])\n",
    "\n",
    "        print(f\"Features shape after cleaning: {X.shape}\")\n",
    "        print(f\"Number of categories: {len(y.unique())}\")\n",
    "        print(\"Checking for infinite values:\", np.any(np.isinf(X)))\n",
    "        print(\"Checking for NaN values:\", np.any(np.isnan(X)))\n",
    "\n",
    "        # Split and train\n",
    "        print(\"\\nSplitting data and training model...\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "\n",
    "        # Define parameter grid for search\n",
    "        print(\"\\nDefining parameter grid for GridSearchCV...\")\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [10, 20, 30, None],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "\n",
    "        # Create base model\n",
    "        rf_base = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "        # Create GridSearchCV object\n",
    "        print(\"\\nStarting GridSearchCV...\")\n",
    "        grid_search = GridSearchCV(\n",
    "            rf_base,\n",
    "            param_grid,\n",
    "            cv=5,\n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1,\n",
    "            verbose=2\n",
    "        )\n",
    "\n",
    "        # Fit grid search\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Print results\n",
    "        print(\"\\nBest parameters found:\")\n",
    "        print(grid_search.best_params_)\n",
    "        print(\"\\nBest cross-validation score:\")\n",
    "        print(f\"{grid_search.best_score_:.4f}\")\n",
    "\n",
    "        # Use the best model for predictions\n",
    "        rf_classifier = grid_search.best_estimator_\n",
    "        y_pred = rf_classifier.predict(X_test)\n",
    "        y_pred_proba = rf_classifier.predict_proba(X_test)\n",
    "\n",
    "        # Print metrics\n",
    "        print(\"\\nTest Set Performance Metrics:\")\n",
    "        print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "        print(f\"Macro Precision: {precision_score(y_test, y_pred, average='macro'):.4f}\")\n",
    "        print(f\"Macro Recall: {recall_score(y_test, y_pred, average='macro'):.4f}\")\n",
    "\n",
    "        print(\"\\nDetailed Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        # Confusion Matrix Plot\n",
    "        plt.figure(figsize=(15, 12))  # Increased size for many categories\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Greens')\n",
    "        plt.title('Normalized Confusion Matrix')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.yticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('confusion_matrix.png')\n",
    "        plt.close()\n",
    "\n",
    "        # ROC Curves\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        categories = np.unique(y)\n",
    "        colors = plt.cm.rainbow(np.linspace(0, 1, len(categories)))\n",
    "\n",
    "        for i, (color, category) in enumerate(zip(colors, categories)):\n",
    "            y_test_binary = (y_test == category).astype(int)\n",
    "            y_score = y_pred_proba[:, i]\n",
    "            fpr, tpr, _ = roc_curve(y_test_binary, y_score)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, color=color, lw=2,\n",
    "                     label=f'{category[:15]}... (AUC = {roc_auc:.2f})')\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves by Category')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('roc_curves.png')\n",
    "        plt.close()\n",
    "\n",
    "        print(\"\\nPlots have been saved to:\")\n",
    "        print(\"- confusion_matrix.png\")\n",
    "        print(\"- roc_curves.png\")\n",
    "\n",
    "        # Save the model\n",
    "        print(\"\\nSaving the model...\")\n",
    "        joblib.dump(rf_classifier, 'random_forest_model.joblib')\n",
    "        print(\"Model saved successfully!\")"
   ],
   "id": "d2f7739350d4a618"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Output\n",
    "The model's performance across 21 product categories shows promising results, as evidenced by the ROC curves and confusion matrix. The ROC curves demonstrate strong classification ability with AUC scores ranging from 0.69 to 0.90, with Cell Phones & Accessories and Grocery & Gourmet categories performing exceptionally well (AUC = 0.90), while Sports & Outdoors shows room for improvement (AUC = 0.69). The normalized confusion matrix reveals a distinct diagonal pattern, indicating good classification accuracy across categories, with Electronics and Cell Phones showing particularly strong performance (0.58 and 0.51 respectively). However, some categories like Musical Instruments (0.14) show more confusion with other categories, suggesting that certain product types may need additional feature engineering or data to improve classification accuracy.\n",
    "\n",
    "__Confusion matrix__\n",
    "![Confusion matrix](confusion_matrix.png)\n",
    "\n",
    "__ROC curves__\n",
    "![ROC curves](roc_curves.png)"
   ],
   "id": "778ed4ddda70c90b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "708cc84e50b21df7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
